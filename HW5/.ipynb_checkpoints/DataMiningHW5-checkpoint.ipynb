{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">EE 380L: Data Mining</p>\n",
    "# <p style=\"text-align: center;\">Assignment 5</p>\n",
    "## <p style=\"text-align: center;\">Total points: 95   </p>\n",
    "## <p style=\"text-align: center;\">Due: November 24th (11/24/2020) submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas. But be sure to include name and UT eID for both students. \n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)* For the descriptive questions, you can write down the solution in paper and embed a picture of it to the notebook or type it out.\n",
    "\n",
    "### Additional instructions : \n",
    "* In order to embed the image into notebook, convert the cell to Markdown and drag-drop the image, you should be able to view them before you submit.\n",
    "\n",
    "* Make sure to submit the notebook with filename as your eID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name(s)\n",
    "1. \n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 : Bayesian Belief Networks (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Question 1](https://i.imgur.com/3ayVbFi.jpeg) \n",
    "\n",
    "All nodes are binary and can take 0/1 values\n",
    "\n",
    "The probabilities are given below:\n",
    "\n",
    "P(Bark = 1) = 0.05   \n",
    "P(Rain = 1) = 0.01\n",
    "\n",
    "\n",
    "P(Scared = 1 | Bark = 0, Rain = 0) = 0.001  \n",
    "P(Scared = 1 | Bark = 0, Rain = 1) = 0.1  \n",
    "P(Scared = 1 | Bark = 1, Rain = 0) = 0.8  \n",
    "P(Scared = 1 | Bark = 1, Rain = 1) = 0.9  \n",
    "\n",
    "P(Hides = 1 | Scared = 1) = 0.95  \n",
    "P(Hides = 1 | Scared = 0) = 0.05  \n",
    "\n",
    "For the given Bayesian network, Compute the following probabilities :  \n",
    "\n",
    "\n",
    "**(a) (4 pts)** Find the probability that cat hides = 1.  \n",
    "**(b) (4 pts)** Given that cat got scared (Scared = 1), what is the probability that it rained (Rain = 1)?  \n",
    "**(c) (7 pts)** Given that cat got scared (Scared = 1) and the dog barked (Bark = 1), what is the probability that it rained (Rain = 1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - **Random Forest (30 pts)**  \n",
    "\n",
    "The goal of this problem is to explore the effect of feature selection using  the following dataset (same as in HW 4) https://www.kaggle.com/wendykan/lending-club-loan-data\n",
    "\n",
    "Since the dataset is really huge, we will use only a certain set of features and samples to build our model. We will also use only two classes instead of all.\n",
    "\n",
    "The modified dataset with reduced number of samples has been prepared for your use. The file can be downloaded using the code below. You can also find it [here](https://drive.google.com/file/d/1Gv_N1rHLqDizxUck6l06BfniR30Pw0Zs/view?usp=sharing) in case you have a different environment and this code does not run.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ggID='1Gv_N1rHLqDizxUck6l06BfniR30Pw0Zs'  \n",
    "ggURL='https://drive.google.com/uc?export=download'  \n",
    "filename=\"$(curl -sc /tmp/gcokie \"${ggURL}&id=${ggID}\" | grep -o '=\"uc-name.*</span>' | sed 's/.*\">//;s/<.a> .*//')\"  \n",
    "getcode=\"$(awk '/_warning_/ {print $NF}' /tmp/gcokie)\"  \n",
    "\n",
    "if [ -e \"${filename}\" ]; then\n",
    "    echo 'File already exists'\n",
    "else\n",
    "    curl -Lb /tmp/gcokie \"${ggURL}&confirm=${getcode}&id=${ggID}\" -o \"${filename}\"  \n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('loan.csv')\n",
    "df = dataset.fillna(0)\n",
    "\n",
    "def LoanResult(status):\n",
    "    if (status == 'Fully Paid') or (status == 'Current'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['loan_status'] = df['loan_status'].apply(LoanResult)\n",
    "\n",
    "df = df[['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate', 'installment', 'grade', 'sub_grade',\n",
    "             'emp_length', 'home_ownership','annual_inc', 'verification_status', 'loan_status',\n",
    "             'purpose','addr_state', 'dti','open_acc', 'pub_rec', 'revol_bal', 'revol_util', \n",
    "             'initial_list_status', 'recoveries','collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt',\n",
    "             'application_type', 'tot_coll_amt', 'tot_cur_bal', 'avg_cur_bal', 'chargeoff_within_12_mths',\n",
    "             'pub_rec_bankruptcies', 'tax_liens', 'debt_settlement_flag']]\n",
    "df_cat = df.select_dtypes(exclude=['int64', 'float64'])\n",
    "df = pd.get_dummies(df, df_cat.columns.values)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the `loan_status` column as the target column.  \n",
    "\n",
    "\n",
    "**Part 1: (3 pts)** Perform [Min-Max Scaling](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) on the dataset. \n",
    "\n",
    "**Part 2: (5 pts)** Split the dataset into train and test set with 25% data in test set and print the total number of features. Use this dataset to create a `RandomForestClassifier(n_estimators=5, random_state=42)` model and print the [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) to show the precision, recall and F1 score based on the test set.  \n",
    "\n",
    "**Part 3: (6 pts)** Use [$\\chi^2$](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html) test to select the top 100, 30 and 10 features using [SelectKBest](https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection) module. Train a random forest model and print the [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) for each of the trained models.  \n",
    "\n",
    "**Note:** $\\chi^2$ test requires non-negative values only for all features. Since we have performed Min-Max scaling previously (where the default behavior is to scale features between 0 and 1, there should not be any problem performing this test.)   \n",
    "\n",
    "**Part 4: (6 pts)** [Plot the ROC curves](https://github.com/justmarkham/scikit-learn-tips/blob/master/notebooks/21_plot_roc_curve.ipynb) for all of the 4 models.  \n",
    "\n",
    "**Part 5: (8 pts)** Plot the feature importance for each of the 4 random forest models that you have trained to show the top 5 features. ([Get feature names after feature selection](https://stackoverflow.com/a/43765224), [Plot feature importance using Pandas and matplotlib](https://stackoverflow.com/a/51520906))  \n",
    "\n",
    "**Part 6: (2 pts)** What do you observe from the ROC curves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 : Logistic Regression with Regularization and Decision Tree (25 pts)\n",
    "\n",
    "The goal of this problem is to explore the effect of regularization on logistic regression for binary classification, we will be using the diabetes dataset. \n",
    "This dataset is used to predict if a person is having \n",
    "diabetes based on feature variables including blood pressure, bmi, age etc. The target variable is stored in \"outcome\" column.\n",
    "\n",
    "* Load the \"diabetes.csv\" and partition it into features (X) and the target label (y) for classification task. Then, use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split data into training and testing: test_size=0.33, random_state=42. \n",
    "\n",
    "\n",
    "* We need to use [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Instead of fitting a model on the original data, we use StandardScaler to center each feature. Also remember that when we have training and testing data, we fit preprocessing parameters on training data and apply them to all testing data. You should scale only the features (independent variables), not the target variable y. \n",
    "\n",
    "   Note: X should have 8 features.\n",
    "\n",
    "\n",
    "**Part 1: (6 pts)** Fit a [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model with penalty $l2$\n",
    "(Ridge Regularization) for the following values of regularization  C = $[0.0001,0.001,0.1,10,100]$ using the training data. Report the accuracy score on the test data averaged over 5 runs of the model for each of the C values. \n",
    "\n",
    "  Note : Smaller values of C indicate stronger regularization\n",
    "\n",
    "    \n",
    "\n",
    "**Part 2: (6 pts)** Fit a [Decision tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) classifier on the training data, and report the accuracy score on the test data averaged over 5 runs. Briefly explain which of the models performed the best Logistic Regression + regularization or Decision Tree Classifier and why. \n",
    "\n",
    "\n",
    "* Now, We will check if the decision boundary from logistic regression is linear by using a 2D plot.\n",
    "\n",
    "\n",
    "**Part 3: (4 pts)** Select the top two most important features ([Feature importance](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_)) using the training data with a Decision Tree Classifier and random_state = 10. Subset the train and test data to have only the selected features. This will be used as the training and test data for part $4$.\n",
    "\n",
    "\n",
    "**Part 4: (8 pts)** Fit a [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model with penalty = $l2$, C = 10 (Ridge Regularization) and random state = 0 for the training data from part $3$ . Plot the decision boundary of the logistic regression model with the two features, as X and Y axis. Here is an [example](https://scikit-learn.org/stable/auto_examples/linear_model/plot_iris_logistic.html) . Plot the scatter points for the test data, on the same graph showing the two classes as two different color. \n",
    "\n",
    "  * Hint : You can use the below limits for plotting the decision boundary, where $X[:,0]$ indicates feature 1 values and $X[:,1]$ indicates feature 2 values of the train dataset. \n",
    "\n",
    "     $ x_\\min, x_\\max = X[:, 0].min() - .5, X[:, 0].max() + .5 $ \n",
    "\n",
    "     $ y_\\min, y_\\max = X[:, 1].min() - .5, X[:, 1].max() + .5 $\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading dataset and pre-processing (**1 pt**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 (**6 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 (**6 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 (**4 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 (**8 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 - Comparison of different ensembles method for classification (25 pts)\n",
    "\n",
    "In this question, we will compare performance of different ensemble methods for classification problems: [Bagging](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html), [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html), [GradientBoosting](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html), and [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) Classifiers.\n",
    "\n",
    "[Spam Classification Data](https://archive.ics.uci.edu/ml/datasets/Spambase) of UCI will be used (you can use the data provided: 'spam_uci.csv'). Don't worry about column names. The last column represents target label, 1 if spam and zero otherwise.\n",
    "\n",
    "* Load the data and partition it into features (X) and the target label (y) for classification task. Then, use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split data into training and testing: test_size=0.33, random_state=42. \n",
    "\n",
    "\n",
    "\n",
    "**Part 1: (4 pts)** Use a Decision Tree Classifier with random_state = 10 and Logistic Regression with random_state = 10 and solver =\"lbfgs\" for the spam classification problem. Report the accuracy_score and roc_auc_score on the test data for each classifier.\n",
    "\n",
    "\n",
    "**Part 2: (8 pts)** Create an ensemble of 50 classifiers (i.e n_estimators = 50) with random_state = 10 for [bagging](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) with base classifier as Decision Tree Classifier and Logistic Regression from part $1$ . Report accuracy_score and roc_auc_score on the test data for both the Bagging classifiers. Compare the results and breifly explain the effect of using bagging for the spam classification problem for both the Logistic Regression and Decision Tree base classifier.\n",
    "\n",
    "\n",
    "* Now we will look at the effect of other ensemble methods on this problem.\n",
    "\n",
    "\n",
    "**Part 3: (5 pts)** Use a [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to classify whether an email is spam. Report your testing accuracy ([accuracy_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)) and [roc_auc_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score). You will need [predict_proba](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba) for roc_auc_score. \n",
    "\n",
    "\n",
    "**Part 4: (5 pts)** Use [Gradient Boosting Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) (GBDT), and [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier) for the spam classification problem.  Report  accuracy_score and roc_auc_score on the test data for each algorithm. \n",
    "\n",
    "  Note : For part 3 and 4 find the best values for the hyper parameters of each of the models by using GridSearchCV. \n",
    "\n",
    "\n",
    "**Part 5: (3 pts)** Briefly explain which of the three ensemble method above from Part 3&4 performed the best and why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and pre-processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 (**4 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 (**8 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 (**5 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 (**5 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 5 (**3 pts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
